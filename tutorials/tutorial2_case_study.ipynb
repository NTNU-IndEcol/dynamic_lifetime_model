{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - case study on Norwegian dishwashers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes the calculations behind a case study on household dishwashers in Norway in the years 1950-2050. \n",
    "\n",
    "The notebook is divided into four parts:\n",
    "1. Imports and basic setup - includes Python imports and basic variable definition;\n",
    "2. Data preprocessing - includes parameter interpolation and regression, and the calculation of the number of dwellings (first driver behind the stock of dishwashers);\n",
    "3. Retrospective analysis - includes model calculations for the years 1950-2022, including the calculation of the product ownership per dwelling (the second driver behind the stock of dishwashers) and its extrapolation until 2050;\n",
    "4. Prospective analysis - includes model calculations for the years 1950-2050;\n",
    "5. Plotting and exporting - visualization of the results.\n",
    "\n",
    "More details can be found in the publication:\n",
    "> Krych, K., Müller, DB. & Pettersen, JB. (2024). The ‘nature’ and ‘nurture’ of product lifetimes in dynamic stock modeling. Journal of Industrial Ecology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "import dynamic_lifetime_model as dlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durable = 'dishwasher'\n",
    "MyYears_retro = list(range(1950, 2022+1))\n",
    "MyYears_full = list(range(1950, 2050+1))\n",
    "excel = 'tutorial2_data.xlsx'\n",
    "overwrite = False\n",
    "export_figs_to_pdf = True\n",
    "export_data_to_xlsx = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to overlay data in preexisting Excel files\n",
    "def df_to_excel_overlay(excel, df, sheet_name):\n",
    "    writer = pd.ExcelWriter(excel, mode='a', if_sheet_exists=\"overlay\", engine='openpyxl') \n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False,startrow=1, header=False)\n",
    "    writer.close()\n",
    "\n",
    "# function used to save data in Excel files without deleting other sheets (for Supplementary Information)\n",
    "def df_to_excel_SI(excel, df, sheet_name):\n",
    "    writer = pd.ExcelWriter(excel, mode='a', if_sheet_exists=\"overlay\", engine='openpyxl') \n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=True,header=True)\n",
    "    writer.close()\n",
    "\n",
    "excel_SI = 'SI_The_nature_and_nurture_of_product_lifetimes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is requires as multiple of the parameters used in the study are not full time series, thus interpolation or regression is needed. Using the obtained time series, we calculate the number of dwellings, which is one of the two drivers for the number of dishwashers in the system (the other being product ownership per dwelling - POpD). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflows of dishwashers (I) - interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inflows_interpolation(df_d, MyYears):\n",
    "    min_year = min(df_d['time']) # the first year with data\n",
    "    max_year = max(df_d['time']) # the last year with data\n",
    "    if min_year > MyYears[0]:\n",
    "        df_d = pd.concat([df_d, pd.DataFrame({\"time\": [MyYears[0]], \"value\": [0]})], ignore_index=True)\n",
    "        df_d = pd.concat([df_d, pd.DataFrame({\"time\": [min_year-1], \"value\": [0]})], ignore_index=True)\n",
    "    if max_year < MyYears[-1]:\n",
    "        last_value = df_d[df_d['time']==max_year]['value'].item()\n",
    "        df_d = pd.concat([df_d, pd.DataFrame({\"time\": [MyYears[-1]], \"value\": [last_value]})], ignore_index=True)\n",
    "    df_d = df_d.groupby('time').mean(numeric_only=True).reset_index()\n",
    "    x_data = df_d['time']\n",
    "    y_data = df_d['value']\n",
    "    f_linear = interp1d(x_data, y_data)\n",
    "    return f_linear(MyYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_data = pd.read_excel(excel, sheet_name='I_data')\n",
    "df_i_ip = pd.DataFrame(data=perform_inflows_interpolation(df_i_data, MyYears_retro),\n",
    "                       index=pd.MultiIndex.from_product([MyYears_retro], names=['time']), columns=['value'])\n",
    "df_i_ip = df_i_ip.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_i_ip,'I')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People per dwelling (PpD) - regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x, ti, a, C0, C1):\n",
    "    \"\"\"\n",
    "    ti: inflection time\n",
    "    a: slope\n",
    "    C0: start value\n",
    "    C1: end value\n",
    "    x: vector of observation points (time)\n",
    "    \"\"\"\n",
    "    return (C1 - C0) / (1 + np.exp(-a * (x - ti))) + C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppd_data = pd.read_excel(excel, sheet_name='PpD_data')\n",
    "lower_bounds = [1900, 0, 5, 0]\n",
    "higher_bounds = [2100, 1, 10, 10]\n",
    "popt, pcov = curve_fit(logistic, df_ppd_data['time'], df_ppd_data['value'], bounds=[lower_bounds, higher_bounds])\n",
    "df_ppd_rg = pd.DataFrame(data=logistic(MyYears_full,*popt), index=pd.MultiIndex.from_product([MyYears_full], names=['time']), columns=['value'])\n",
    "df_ppd_rg = df_ppd_rg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_ppd_rg,'PpD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabins per person (CpP) - regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_logistic(x, ti, a, C0, C1, v):\n",
    "    \"\"\"\n",
    "    ti: inflection time\n",
    "    a: slope\n",
    "    C0: start value\n",
    "    C1: end value\n",
    "    x: vector of observation points (time)\n",
    "    v: assymetry factor\n",
    "    \"\"\"\n",
    "    return (C1 - C0) / (1 + np.exp(-a * (x - ti))) ** (1 / v) + C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpp_data = pd.read_excel(excel, sheet_name='CpP_data')\n",
    "CpP_years = list(range(1900,2050+1))\n",
    "lower_bounds =  [1950, 0, 0,      0, 0]\n",
    "higher_bounds = [1990, 1, 0.0001, 0.12, 10]\n",
    "popt, pcov = curve_fit(asymmetric_logistic, df_cpp_data['time'], df_cpp_data['value'], bounds=[lower_bounds, higher_bounds])\n",
    "df_cpp_rg = pd.DataFrame(data=asymmetric_logistic(CpP_years,*popt), \n",
    "                         index=pd.MultiIndex.from_product([CpP_years], names=['time']), columns=['value'])\n",
    "df_cpp_rg = df_cpp_rg.reset_index()\n",
    "print(popt)\n",
    "plt.plot(df_cpp_rg['time'], df_cpp_rg['value'])\n",
    "plt.scatter(df_cpp_data['time'], df_cpp_data['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_cpp_rg,'CpP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Share of cabins electrified (SoCE) - regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soce = pd.read_excel(excel, sheet_name='SoCE_data', usecols=\"A:D\")\n",
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "x_data, y_data = df_soce['time'], df_soce['value']\n",
    "with np.errstate(divide='ignore'): # to ignore \"RuntimeWarning: divide by zero encountered in...\"\n",
    "    y_data_log = np.log(y_data*100)\n",
    "y_data_log[y_data_log == -np.inf] = 0\n",
    "popt, pcov = curve_fit(linear, x_data, y_data_log)\n",
    "soce = np.exp(popt[0]*np.array(MyYears_full)+popt[1])/100\n",
    "soce[soce >1] = 1\n",
    "soce[:1960-min(df_soce['time'])] = 0 \n",
    "soce[soce <0] = 0\n",
    "df_soce_rg = pd.DataFrame(data=soce, index=pd.MultiIndex.from_product([MyYears_full], names=['time']), columns=['value'])\n",
    "df_soce_rg = df_soce_rg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_soce_rg,'SoCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of dwellings (D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the required time series, the number of dwellings can be calculated. It is a sum of primary dwellings (calculated using the population P and the people per dwelling PpD) and secondary dwellings that are equipped with dishwashers (calculated using population P, cabins per person CpP and share of cabins electrified SoCE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppd = pd.read_excel(excel, sheet_name='PpD')\n",
    "df_p = pd.read_excel(excel, sheet_name='P')\n",
    "df_cpp = pd.read_excel(excel, sheet_name='CpP')\n",
    "df_soce = pd.read_excel(excel, sheet_name='SoCE')\n",
    "df_k_cab = pd.read_excel(excel, sheet_name='k-cab')\n",
    "df_l_cab = pd.read_excel(excel, sheet_name='lambda-cab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_short = df_p[df_p['time']>=1950]\n",
    "df_p_short = df_p_short.reset_index()\n",
    "dwellings = np.array(df_p_short['value']/df_ppd['value'])\n",
    "\n",
    "t = df_cpp['time']\n",
    "s = df_cpp['value']*df_p['value']\n",
    "scale = df_l_cab['value'].values[0]\n",
    "shape = df_k_cab['value'].values[0]\n",
    "sf = np.zeros((len(t), len(t)))\n",
    "for m in range(0, len(t)):  # cohort index\n",
    "    sf[m::,m] = scipy.stats.weibull_min.sf(np.arange(0,len(t)-m), c=shape, loc = 0, scale=scale)\n",
    "\n",
    "# MFA calculations start (assuming sf[0] != 0 and no negative inflows)\n",
    "i = np.zeros(len(t))\n",
    "s_c = np.zeros((len(t), len(t)))\n",
    "i[0] = s[0] / sf[0, 0]\n",
    "s_c[:, 0] = i[0] * sf[:, 0]\n",
    "for m in range(1, len(t)):\n",
    "    i[m] = (s[m] - s_c[m, :].sum()) / sf[m,m]\n",
    "    s_c[m::, m] = i[m] * sf[m::, m]\n",
    "\n",
    "o_c = np.zeros_like(s_c)\n",
    "o_c[1::,:] = -1 * np.diff(s_c,n=1,axis=0)\n",
    "o_c[np.diag_indices(len(t))] = i - np.diag(s_c) # allow for outflow in year 0 already\n",
    "\n",
    "soce = df_soce['value'] # share of cabins electrified\n",
    "soce[soce >1] = 1\n",
    "soce[:1960-min(df_soce['time'])] = 0 \n",
    "soce[soce <0] = 0\n",
    "el_cabins = np.einsum('tc,c->t',s_c[50:,50:],soce)\n",
    "all_dwellings = dwellings+el_cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.DataFrame(data=all_dwellings, index=pd.MultiIndex.from_product([MyYears_full], names=['time']), columns=['value'])\n",
    "df_d = df_d.reset_index()\n",
    "df_d['unit'] = 'dwellings'\n",
    "df_d['source'] = 'calculated using a dwelling sub-model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_d,'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrospective analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrospective analysis runs during years 1950-2022 and is an inflow-driven model used to calculate the stock of dishwashers. The stock then serves to calculate product ownership per dwelling (POpD) using the number of dwellings calculated above. Then, the ownership per dwelling is extrapolated until 2050, assuming saturation at 1.05 dishwashers/dwelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_retro = pd.read_excel(excel, sheet_name='I')['value'].values\n",
    "shape = pd.read_excel(excel, sheet_name='k')['value'].values\n",
    "scale = pd.read_excel(excel, sheet_name='lambda')['value'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_retro = dlm.DynamicLifetimeModel(i=i_retro, t=MyYears_retro)\n",
    "model_retro.lt = {'Type': 'Weibull', \n",
    "          'Scale': model_retro.create_2Darray(scale), #two-dimensional parameter (time by cohort)\n",
    "          'Shape': model_retro.create_2Darray(shape)  #two-dimensional parameter (time by cohort)\n",
    "          }\n",
    "model_retro.compute_inflow_driven_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate product ownership per dwelling (POpD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.read_excel(excel, sheet_name='D')\n",
    "df_d_retro = df_d[df_d['time']<=2022]\n",
    "d_retro = df_d_retro['value'].values\n",
    "d = df_d['value'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popd_retro = model_retro.s/d_retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_popd_data = pd.read_excel(excel, sheet_name='POpD_data')\n",
    "plt.scatter(df_popd_data['time'], df_popd_data['value'])\n",
    "plt.plot(MyYears_retro, popd_retro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolate POpD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popd_max = 1.05\n",
    "def logistic2(x, ti, a, C, C1):\n",
    "    C0 = C-(C1-C)\n",
    "    return (C1 - C0) / (1 + np.exp(-a * (x - ti))) + C0\n",
    "slope = (popd_retro[-1]-popd_retro[-5])/(MyYears_retro[-1]-MyYears_retro[-5])*popd_max/(popd_retro[-1]*(popd_max-popd_retro[-1]))\n",
    "popd_full = [x for x in popd_retro[:-1]] + list(logistic2(np.arange(2019,2050-3+1),2019,slope,popd_retro[-1],popd_max))\n",
    "plt.plot(MyYears_retro, popd_retro, label='historical')\n",
    "plt.plot(MyYears_full[2022-1950:], popd_full[2022-1950:], label='extrapolated')\n",
    "plt.axvline(x=2022,color=\"grey\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_popd = pd.DataFrame(data=popd_full, index=pd.MultiIndex.from_product([MyYears_full], names=['time']), columns=['value'])\n",
    "df_popd = df_popd.reset_index()\n",
    "df_popd['unit'] = 'dishwashers/dwelling'\n",
    "df_popd['source'] = 'retrospective model and extrapolation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    df_to_excel_overlay(excel,df_popd,'POpD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prospective analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters derived in the previous stages of this tutorial, it is possible to run a stock-driven analysis for the years 1950-2050. Five models are created, including a baseline model and four lifetime extension models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MyYears_full\n",
    "popd = pd.read_excel(excel, sheet_name='POpD')['value'].values\n",
    "d = pd.read_excel(excel, sheet_name='D')['value'].values\n",
    "stock = popd*d\n",
    "shape = pd.read_excel(excel, sheet_name='k')['value'].values\n",
    "scale = pd.read_excel(excel, sheet_name='lambda')['value'].values\n",
    "lt_ext =  0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "model_0.lt = {'Type': 'Weibull', \n",
    "          'Scale': model_0.create_2Darray(scale),\n",
    "          'Shape': model_0.create_2Darray(shape)\n",
    "          }\n",
    "model_0.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lifespan labelling (cohort effect)\n",
    "model_1 = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "model_1.lt = {'Type': 'Weibull', \n",
    "                'Scale': model_1.create_2Darray(scale), \n",
    "                'Shape': model_1.create_2Darray(shape)\n",
    "                }\n",
    "model_1.lt['Scale'] = model_1.add_cohort_effect(model_1.lt['Scale'],1+lt_ext, 2026, ref='relative')\n",
    "model_1.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tax relief/subsidy (period effect)\n",
    "model_2 = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "model_2.lt = {'Type': 'Weibull', \n",
    "                'Scale': model_2.create_2Darray(scale), \n",
    "                'Shape': model_2.create_2Darray(shape)\n",
    "                }\n",
    "model_2.lt['Scale'] = model_2.add_period_effect(model_2.lt['Scale'],1+lt_ext,2035, ref='relative', trans_start=2026, trans_type='logistic')\n",
    "model_2.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affordable spare parts (age-cohort effect)\n",
    "model_3 = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "model_3.lt = {'Type': 'Weibull', \n",
    "                'Scale': model_3.create_2Darray(scale), \n",
    "                'Shape': model_3.create_2Darray(shape)\n",
    "                }\n",
    "model_3.lt['Scale'] = model_1.add_cohort_effect(model_3.lt['Scale'],1+lt_ext,2035, ref='relative', ages=np.arange(10), trans_start=2026, trans_type='logistic')\n",
    "model_3.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarranty (age-period effect)\n",
    "model_4 = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "model_4.lt = {'Type': 'Weibull', \n",
    "                'Scale': model_4.create_2Darray(scale), \n",
    "                'Shape': model_4.create_2Darray(shape)\n",
    "                }\n",
    "model_4.lt['Scale'] = model_4.add_period_effect(model_4.lt['Scale'],1+lt_ext,2035, ref='relative', ages=np.arange(5), trans_start=2026, trans_type='logistic')\n",
    "model_4.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting and exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations are successful, therefore we can plot the results and export them if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"rocket\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "fig.set_dpi(800)\n",
    "plt.plot(t[:76],model_0.i[:76], label='Historical data', color='gray', linewidth=2)\n",
    "plt.plot(t[75:],model_0.i[75:], label='Scenario 0: baseline', linewidth=2, color=palette[0])\n",
    "plt.plot(t[75:],model_1.i[75:], label='Scenario 1: lifespan labelling', linewidth=2, linestyle=(0, (1, 1)), color=palette[1])\n",
    "plt.plot(t[75:],model_2.i[75:], label='Scenario 2: repair subsidies', linewidth=2, linestyle='--', color=palette[2])\n",
    "plt.plot(t[75:],model_3.i[75:], label='Scenario 3: spare parts', linewidth=2, linestyle='-.', color=palette[3])\n",
    "plt.plot(t[75:],model_4.i[75:], label='Scenario 4: guarantee', linewidth=2, linestyle=':', color=palette[4])\n",
    "plt.axvline(2025, color='gray', linestyle='--')\n",
    "fig.legend(fontsize=9, bbox_to_anchor=(1,0.5),loc=\"center left\", handlelength=4)\n",
    "plt.xlim(1990-2,2050+2)\n",
    "plt.ylim(0,)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales of new dishwashers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('Fig5.pdf', format='pdf', bbox_inches = \"tight\")\n",
    "if export_data_to_xlsx:\n",
    "    data = np.concatenate(([model_0.i],[model_1.i],[model_2.i],[model_3.i],[model_4.i]), axis=0)\n",
    "    col_names = ['baseline', 'scenario 1', 'scenario 2', 'scenario 3', 'scenario 4']\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([MyYears_full], names=['time']), columns=col_names)\n",
    "    df_to_excel_SI(excel_SI,df,'Figure 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sales decrease in 2050 relative to baseline:\" \n",
    "      f\"\\nScenario 1: {round((model_1.i[-1]-model_0.i[-1])/model_0.i[-1]*100,1)}%\"\n",
    "      f\"\\nScenario 2: {round((model_2.i[-1]-model_0.i[-1])/model_0.i[-1]*100,1)}%\"\n",
    "      f\"\\nScenario 3: {round((model_3.i[-1]-model_0.i[-1])/model_0.i[-1]*100,1)}%\"\n",
    "      f\"\\nScenario 4: {round((model_4.i[-1]-model_0.i[-1])/model_0.i[-1]*100,1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - age of stock and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "gs = fig.add_gridspec(1, 2,wspace=0.2)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(t[:76],model_0.calculate_age_stock(scale_by_inflow=True)[:76], color='gray', linewidth=2)\n",
    "ax1.plot(t[75:],model_0.calculate_age_stock(scale_by_inflow=True)[75:], linewidth=2, color=palette[0])\n",
    "ax1.plot(t[75:],model_1.calculate_age_stock(scale_by_inflow=True)[75:], linewidth=2, linestyle=(0, (1, 1)), color=palette[1])\n",
    "ax1.plot(t[75:],model_2.calculate_age_stock(scale_by_inflow=True)[75:], linewidth=2, linestyle='--', color=palette[2])\n",
    "ax1.plot(t[75:],model_3.calculate_age_stock(scale_by_inflow=True)[75:], linewidth=2, linestyle='-.', color=palette[3])\n",
    "ax1.plot(t[75:],model_4.calculate_age_stock(scale_by_inflow=True)[75:], linewidth=2, linestyle=':', color=palette[4])\n",
    "ax1.axvline(2025, color='gray', linestyle='--')\n",
    "ax1.set_xlim(2000,2050)\n",
    "ax1.set_ylim(0,18)\n",
    "ax1.set_title('Age of stock')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(t[:76],model_0.calculate_age_outflow(scale_by_inflow=True)[:76], label='Historical data', color='gray', linewidth=2)\n",
    "ax2.plot(t[75:],model_0.calculate_age_outflow(scale_by_inflow=True)[75:], label='Scenario 0: baseline', linewidth=2, color=palette[0])\n",
    "ax2.plot(t[75:],model_1.calculate_age_outflow(scale_by_inflow=True)[75:], label='Scenario 1: lifespan labelling', linewidth=2, linestyle=(0, (1, 1)), color=palette[1])\n",
    "ax2.plot(t[75:],model_2.calculate_age_outflow(scale_by_inflow=True)[75:], label='Scenario 2: repair subsidies', linewidth=2, linestyle='--', color=palette[2])\n",
    "ax2.plot(t[75:],model_3.calculate_age_outflow(scale_by_inflow=True)[75:], label='Scenario 3: spare parts', linewidth=2, linestyle='-.', color=palette[3])\n",
    "ax2.plot(t[75:],model_4.calculate_age_outflow(scale_by_inflow=True)[75:], label='Scenario 4: guarantee', linewidth=2, linestyle=':', color=palette[4])\n",
    "ax2.axvline(2025, color='gray', linestyle='--')\n",
    "ax2.set_xlim(2000,2050)\n",
    "ax2.set_ylim(0,18)\n",
    "ax2.set_title('Age of outflows')\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.5,-0.02), loc=\"upper center\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - hazard matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_heatmap(matrix, ax=None, colorbar=True):\n",
    "    if ax == None:\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        ax = plt.gca()\n",
    "    mask = np.zeros_like(matrix)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    plot_matrix_mask = np.ma.masked_array(matrix, mask=mask)\n",
    "    img = ax.imshow(plot_matrix_mask,cmap='Oranges')\n",
    "    ax.set_xticks(ticks=np.arange(0, t[-1]-t[40]+1, 15), labels=t[40::15], rotation=90)\n",
    "    ax.set_yticks(ticks=np.arange(0, t[-1]-t[40]+1, 15), labels=t[40::15])\n",
    "    if colorbar:\n",
    "        cbar = plt.colorbar(img, ax=ax)\n",
    "        # cbar = plt.colorbar(img,cax=fig.add_axes([0.98, 0.11, 0.02, 0.77]))\n",
    "        cbar.ax.set_ylabel('Hazard rate')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = fig.add_gridspec(2, 3,wspace=0.5, hspace=0.5)\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:], ax=ax0, colorbar=False)\n",
    "ax0.set_title('Scenario 0: baseline')\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "plot_matrix_heatmap(model_1.hz[40:, 40:], ax=ax1, colorbar=False)\n",
    "ax1.set_title('Scenario 1: ecodesign and labelling')\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "plot_matrix_heatmap(model_2.hz[40:, 40:], ax=ax2, colorbar=False)\n",
    "ax2.set_title('Scenario 2: repair subsidies')\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "plot_matrix_heatmap(model_3.hz[40:, 40:], ax=ax3, colorbar=False)\n",
    "ax3.set_title('Scenario 3: spare parts')\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "plot_matrix_heatmap(model_4.hz[40:, 40:], ax=ax4, colorbar=False)\n",
    "ax4.set_title('Scenario 4: warranties')\n",
    "\n",
    "fig.suptitle('Hazard matrix', fontsize=20)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = fig.add_gridspec(2, 3,wspace=0.5, hspace=0.5)\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:]-model_0.hz[40:, 40:], ax=ax0, colorbar=False)\n",
    "ax0.set_title('Scenario 0: baseline')\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:]-model_1.hz[40:, 40:], ax=ax1, colorbar=False)\n",
    "ax1.set_title('Scenario 1: ecodesign and labelling')\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:]-model_2.hz[40:, 40:], ax=ax2, colorbar=False)\n",
    "ax2.set_title('Scenario 2: repair subsidies')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:]-model_3.hz[40:, 40:], ax=ax3, colorbar=False)\n",
    "ax3.set_title('Scenario 3: spare parts')\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "plot_matrix_heatmap(model_0.hz[40:, 40:]-model_4.hz[40:, 40:], ax=ax4, colorbar=False)\n",
    "ax4.set_title('Scenario 4: warranties')\n",
    "\n",
    "plt.suptitle('Hazard matrix (baseline minus given scenario)', fontsize=16)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88a8cd6dab7e39e26651f15ad9527b438eba8983743c187474a3cdf275f3d522"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
