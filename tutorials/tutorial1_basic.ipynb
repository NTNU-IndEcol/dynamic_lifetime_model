{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - basics of DLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook demonstrates basic functionalities of the dynamic_lifetime_model (DLM) framework. \n",
    "\n",
    "The notebook is divided into three parts:\n",
    "1. Imports and basic setup - includes Python imports and basic variable definition;\n",
    "2. Comparing lifetime functions - visualizes the differences between the hazard function, being the basis of DLM, and the corresponding survival function and probability function;\n",
    "3. Creating simple models with 'nature' and 'nurture' interventions - demonstrates the changes introduced in a simple system through 'nature' and 'nurture' interventions, i.e., cohort and period effects, respectively. \n",
    "\n",
    "More details can be found in the publication:\n",
    "> Krych, K., Müller, DB. & Pettersen, JB. (2024). The ‘nature’ and ‘nurture’ of product lifetimes in dynamic stock modeling. Journal of Industrial Ecology.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The average lifetime $\\mu$ is described by equation $\\mu = \\lambda \\Gamma (1+1/k) $, where $\\lambda$ is the scale parameter, $\\Gamma$ is the gamma function and $k$ is the shape parameter. Consequently, if we keep the shape parameter constant, then an increase of 10% in average lifetime corresponds to an increase of 10% in the scale parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, 'ODYM/odym/modules')))\n",
    "import dynamic_stock_model as dsm\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "import dynamic_lifetime_model as dlm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time vector\n",
    "t = np.arange(1950,2050+1)\n",
    "stock = 10000 / (1 + np.exp(-0.15 * (t - 2010))) # logistic stock saturating at 10000 units\n",
    "\n",
    "# lifetime data\n",
    "scale = 10 # scale parameter of the Weibull distribution (often denoted as lambda)\n",
    "shape = 2 # shape parameter of the Weibull distribution (often denoted as k)\n",
    "lt_ext = 0.2\n",
    "effect_year = 2026\n",
    "\n",
    "export_figs_to_pdf = True\n",
    "export_figs_to_xlsx = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to save data in Excel files without deleting other sheets (for Supplementary Information)\n",
    "def df_to_excel_SI(excel, df, sheet_name):\n",
    "    writer = pd.ExcelWriter(excel, mode='a', if_sheet_exists=\"overlay\", engine='openpyxl') \n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=True,header=True)\n",
    "    writer.close()\n",
    "\n",
    "excel_SI = 'SI_The_nature_and_nurture_of_product_lifetimes.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing lifetime functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic assumption of DLM is that all the stock and flow calculations are based on the hazard function. Below, we see three different lifetime functions (the probability function, survival function, and the hazard function) plotted for the Weibull distributions $W(t,10,2)$ and $W(t,10 \\cdot 120\\%,2)$ and a third distribution, where the lifetime is increased from $W(t,10,2)$ by 20% after the 10th year. We see that the third distribution results in values that overlap distribution 1 and 2 only in the case of the hazard function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate hazard functions\n",
    "hz_1 = dlm.compute_hz_from_lt_par(t,{'Type': 'Weibull', 'Shape': dlm.create_2Darray(t,shape), 'Scale': dlm.create_2Darray(t,scale)})[:,0]\n",
    "hz_2 = dlm.compute_hz_from_lt_par(t,{'Type': 'Weibull', 'Shape': dlm.create_2Darray(t,shape), 'Scale': dlm.create_2Darray(t,scale*(1+lt_ext))})[:,0]\n",
    "hz_12 = np.concatenate((hz_1[:11], hz_2[11:])) #switch to hz_2 after the 10th year\n",
    "\n",
    "# calculate survival functions\n",
    "sf_1 = dlm.compute_sf_from_hz(hz_1)\n",
    "sf_2 = dlm.compute_sf_from_hz(hz_2)\n",
    "sf_12 = dlm.compute_sf_from_hz(hz_12)\n",
    "\n",
    "# calculate probability functions\n",
    "pdf_1 = dlm.compute_pdf_from_sf(sf_1)\n",
    "pdf_2 = dlm.compute_pdf_from_sf(sf_2)\n",
    "pdf_12 = dlm.compute_pdf_from_sf(sf_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 3))\n",
    "if export_figs_to_pdf:\n",
    "    fig.set_dpi(800)\n",
    "gs = fig.add_gridspec(1, 3,wspace=0.3)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(np.arange(len(t[70:])), pdf_1[:-70], linestyle='-', linewidth=3, color='tab:orange')\n",
    "ax1.plot(np.arange(len(t[70:])), pdf_2[:-70], linestyle='-', linewidth=3, color='tab:green')\n",
    "ax1.scatter(np.arange(len(t[70:])), pdf_12[:-70], color='black', s=8, zorder=3)\n",
    "ax1.axvline(10, color='gray', linewidth=1, linestyle='--')\n",
    "ax1.set_xlabel('t')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.text(-8,ax1.get_ylim()[1],'A', fontsize=15)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(np.arange(len(t[70:])), sf_1[:-70], linestyle='-', linewidth=3, color='tab:orange')\n",
    "ax2.plot(np.arange(len(t[70:])), sf_2[:-70], linestyle='-', linewidth=3, color='tab:green')\n",
    "ax2.scatter(np.arange(len(t[70:])), sf_12[:-70], color='black', s=8, zorder=3)\n",
    "ax2.axvline(10, color='gray', linewidth=1, linestyle='--')\n",
    "ax2.set_xlabel('t')\n",
    "ax2.set_ylabel('Proportion surviving')\n",
    "ax2.text(-8,ax2.get_ylim()[1],'B', fontsize=15)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.plot(np.arange(len(t[70:])), hz_1[:-70], linestyle='-', linewidth=3, color='tab:orange', label='W(t;10,2) (baseline)', zorder=1)\n",
    "ax3.plot(np.arange(len(t[70:])), hz_2[:-70], linestyle='-', linewidth=3, color='tab:green', label='W(t;12,2) (20% longer)', zorder=2)\n",
    "ax3.scatter(np.arange(len(t[70:])), hz_12[:-70], color='black', label='W(t;10,2) extended by 20% after $t=10$', s=8, zorder=3)\n",
    "ax3.axvline(10, color='gray', linewidth=1, linestyle='--')\n",
    "ax3.set_xlabel('t')\n",
    "ax3.set_ylabel('Hazard rate')\n",
    "ax3.text(-8,ax3.get_ylim()[1],'C', fontsize=15)\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.5,-0.02), loc=\"upper center\", fontsize=10)\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('Fig1.pdf', format='pdf', bbox_inches = \"tight\")\n",
    "if export_figs_to_xlsx:\n",
    "    data = np.concatenate(([pdf_1[:-70]],[pdf_2[:-70]],[pdf_12[:-70]],[sf_1[:-70]],[sf_2[:-70]],[sf_12[:-70]],[hz_1[:-70]],[hz_2[:-70]],[hz_12[:-70]]), axis=0)\n",
    "    col_names = ['pdf: W(t;10,2)', 'pdf: W(t;12,2)', 'pdf: W(t;10,2) extended', \n",
    "                 'sf: W(t;10,2)', 'sf: W(t;12,2)', 'sf: W(t;10,2) extended', \n",
    "                 'hz: W(t;10,2)', 'hz: W(t;12,2)', 'hz: W(t;10,2) extended']\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([np.arange(len(pdf_1[:-70]))], names=['time']), columns=col_names)\n",
    "    df_to_excel_SI(excel_SI,df,'Figure 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating simple models with 'nature' and 'nurture' interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create three instances of the DynamicLifetimeModel class: \n",
    "- a baseline model with only $W(t;10,2)$, \n",
    "- a model with a 'nature' intervention (cohort effect) that increases the lifetime by 20% after 2026, \n",
    "- a model with a 'nurture' intervention (period effect) that increases  the lifetime by 20% after 2026. \n",
    "\n",
    "The first two models are also created using the dynamic_stock_model (DSM) library from ODYM for comparison. The two libraries handle lifetimes differently: DLM uses the hazard function while DSM uses the survival function. By using the hazard function, DLM can model the \"period effects\" case, which cannot easily be done in DSM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling using the dynamic_lifetime_model (DLM) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "DLM = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "DLM.lt = {'Type': 'Weibull', \n",
    "          'Scale': DLM.create_2Darray(scale), #two-dimensional parameter (time by cohort)\n",
    "          'Shape': DLM.create_2Darray(shape)  #two-dimensional parameter (time by cohort)\n",
    "          }\n",
    "DLM.compute_stock_driven_model()\n",
    "\n",
    "# nature intervention - cohort effect\n",
    "DLM_cohort = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "DLM_cohort.lt = {'Type': 'Weibull', \n",
    "                'Scale': DLM_cohort.create_2Darray(scale), \n",
    "                'Shape': DLM_cohort.create_2Darray(shape)\n",
    "                }\n",
    "DLM_cohort.lt['Scale'] = DLM_cohort.add_cohort_effect(DLM_cohort.lt['Scale'],1+lt_ext, effect_year, ref='relative')\n",
    "DLM_cohort.compute_stock_driven_model()\n",
    "\n",
    "# nurture intervention - period effect\n",
    "DLM_period = dlm.DynamicLifetimeModel(s=stock, t=t)\n",
    "DLM_period.lt = {'Type': 'Weibull', \n",
    "                'Scale': DLM_period.create_2Darray(scale), \n",
    "                'Shape': DLM_period.create_2Darray(shape)\n",
    "                }\n",
    "DLM_period.lt['Scale'] = DLM_period.add_period_effect(DLM_period.lt['Scale'],1+lt_ext, effect_year, ref='relative')\n",
    "DLM_period.compute_stock_driven_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling using the dynamic_stock_model (DSM) library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the equivalents of the first two models in the DSM library and compare the results with DLM. As seen below, the difference between the two is negligible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "DSM = dsm.DynamicStockModel(s=stock, t=t)\n",
    "DSM.lt = {'Type': 'Weibull', \n",
    "          'Scale': np.repeat(scale,len(t)), #one-dimensional parameter (cohort)\n",
    "          'Shape': np.repeat(shape,len(t))  #one-dimensional parameters (cohort)\n",
    "          }\n",
    "DSM.compute_stock_driven_model()\n",
    "\n",
    "# nature intervention - cohort effect\n",
    "DSM_cohort = dsm.DynamicStockModel(s=stock, t=t)\n",
    "# to reflect the lifetime increase, we multiply the original values by a multiplier of 1 or more\n",
    "multiplier = np.ones_like(t, dtype=float) \n",
    "multiplier[effect_year-t[0]:] = np.repeat(1+lt_ext, len(multiplier[effect_year-t[0]:])) # increase the values after effect_year\n",
    "DSM_cohort.lt = {'Type': 'Weibull', \n",
    "                'Scale': np.repeat(scale,len(t))*multiplier,\n",
    "                'Shape': np.repeat(shape,len(t))\n",
    "                }\n",
    "DSM_cohort.compute_stock_driven_model()\n",
    "\n",
    "print(f'The relative difference between DLM and DSM is:'\n",
    "      f'\\n - for the \"baseline\" case: {np.sum(np.abs(DLM.i - DSM.i))/np.sum(DSM.i)}'\n",
    "      f'\\n - for the \"cohort effect\" case: {np.sum(np.abs(DLM_cohort.i - DSM_cohort.i))/np.sum(DSM_cohort.i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - inflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see how the different scenarios compare with each other, we plot the results. The year of the intervention is marked by a vertical dashed line. We note that the \"nurture\" intervention has an immediate effect compared to the \"nature\" intervention which takes time as it relies on stock replacement. In either case, the effect could be implemented with a transition period (linear or S-shaped/logistic), which would introduce the change gradually, effectively smoothening the inflow curve seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(t,DLM.i, label='Baseline')\n",
    "plt.plot(t,DLM_cohort.i, label='Cohort effects')\n",
    "plt.plot(t,DLM_period.i, label='Period effects')\n",
    "plt.axvline(effect_year, color='gray', linestyle='--')\n",
    "plt.title('Inflows')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - age of stock and outflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also demonstrate the changes that happen in the system by plotting the mean age of items in stock. Again, we see that the period effect case gives an immediate result while the cohort effect case lags behind. Note that the age values below are scaled by inflows - if they weren't, we would see more fluctuations in age, e.g., the age before 2026 would not have been stable (it would be driven down by the relatively higher inflows of younger items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "gs = fig.add_gridspec(1, 2,wspace=0.2)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(t,DLM.calculate_age_stock(scale_by_inflow=True))\n",
    "ax1.plot(t,DLM_cohort.calculate_age_stock(scale_by_inflow=True))\n",
    "ax1.plot(t,DLM_period.calculate_age_stock(scale_by_inflow=True))\n",
    "ax1.axvline(effect_year, color='gray', linestyle='--')\n",
    "ax1.set_xlim(2000,2050)\n",
    "ax1.set_ylim(0,11.5)\n",
    "ax1.set_title('Age of stock')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(t,DLM.calculate_age_outflow(scale_by_inflow=True), label='Baseline')\n",
    "ax2.plot(t,DLM_cohort.calculate_age_outflow(scale_by_inflow=True), label='Cohort effects')\n",
    "ax2.plot(t,DLM_period.calculate_age_outflow(scale_by_inflow=True), label='Period effects')\n",
    "ax2.axvline(effect_year, color='gray', linestyle='--')\n",
    "ax2.set_xlim(2000,2050)\n",
    "ax2.set_ylim(0,11.5)\n",
    "ax2.set_title('Age of outflows')\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.5,-0.02), loc=\"upper center\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - hazard matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the hazard rate for each time period and cohort. First, we see the hazard matrix for the baseline case, where a clear diagonal pattern indicates that age is the only factor influencing the probability of product discard. In the following plot, we see that the cohort effect introduces a vertical disturbance to the matrix, while and the period effect introduces a horizontal disturbance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum hazard rate among all three models\n",
    "vmax = max(np.max(DLM.hz[40:,40:]), np.max(DLM_cohort.hz[40:,40:]), np.max(DLM_period.hz[40:,40:]))\n",
    "for interval in [0.2, 0.1,0.05, 0.025]:\n",
    "    if vmax/interval > 3 and vmax/interval < 8:\n",
    "        ticks = list(np.arange(0,vmax,interval))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "if export_figs_to_pdf:\n",
    "    fig.set_dpi(800)\n",
    "matrix = DLM.hz[40:,40:]\n",
    "mask = np.zeros_like(matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plot_matrix_mask = np.ma.masked_array(matrix, mask=mask)\n",
    "img = ax.imshow(plot_matrix_mask,cmap='Oranges',vmax=vmax)\n",
    "ax.set_xticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20], rotation=90)\n",
    "ax.set_yticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20])\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_ylabel('Time', fontsize=10)\n",
    "ax.set_xlabel('Cohort', fontsize=10)\n",
    "\n",
    "cbar = plt.colorbar(img, ticks=ticks)\n",
    "cbar.ax.get_yaxis().labelpad = 8\n",
    "cbar.ax.set_ylabel('Hazard rate')\n",
    " \n",
    "ax.text(10,40,'Age', fontsize=10, rotation=45)\n",
    "x = np.flip(np.arange(0,60+1))/2\n",
    "y = 60-x\n",
    "ax.plot((0,30), (60,30), lw=1, color='black')\n",
    "for i in np.arange(60)[::10]:\n",
    "    ax.plot((x[i],x[i]-1), (y[i],y[i]-1), lw=1, color='black')\n",
    "    ax.text(x[i]-4,y[i]-1.5, i, fontsize=10, rotation=45)\n",
    "# ax.plot((0,50),(10,60))\n",
    "plt.tight_layout()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('Fig2.pdf', format='pdf', bbox_inches = \"tight\")\n",
    "if export_figs_to_xlsx:\n",
    "    data = DLM.hz[40:,40:]\n",
    "    df = pd.DataFrame(data=data, index=pd.MultiIndex.from_product([t[40:]], names=['time']), columns=t[40:])\n",
    "    df_to_excel_SI(excel_SI,df,'Figure 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "if export_figs_to_pdf:\n",
    "    fig.set_dpi(800)\n",
    "gs = fig.add_gridspec(1, 2,wspace=0.5)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.text(-18,-10,'A', fontsize=15)\n",
    "matrix = DLM_cohort.hz[40:, 40:]# -DLM.hz[40:, 40:]\n",
    "mask = np.zeros_like(matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plot_matrix_mask = np.ma.masked_array(matrix, mask=mask)\n",
    "# extent = t[0], t[-1], t[-1], t[0]\n",
    "img1 = ax1.imshow(plot_matrix_mask,cmap='Oranges' ,vmax=vmax)\n",
    "ax1.set_xticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20], rotation=90)\n",
    "ax1.set_yticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20])\n",
    "ax1.set_xlabel('Cohort')\n",
    "ax1.set_ylabel('Time')\n",
    "ax1.xaxis.set_ticks_position('top')\n",
    "ax1.xaxis.set_label_position('top')\n",
    "ax1.annotate(text='',xy=(36,35),xytext=(36,28),arrowprops=dict(facecolor='black', width=1.2,headwidth=6,headlength=10))\n",
    "ax1.text(36,28-1,'Cohort effect\\nstarts here',fontsize=9, ha='center', va='bottom')\n",
    "# plt.colorbar(img1, ax=ax1)\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.text(-18,-10,'B', fontsize=15)\n",
    "matrix = DLM_period.hz[40:, 40:]\n",
    "mask = np.zeros_like(matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plot_matrix_mask = np.ma.masked_array(matrix, mask=mask)\n",
    "# extent = t[0], t[-1], t[-1], t[0]\n",
    "img2 = ax2.imshow(plot_matrix_mask,cmap='Oranges',vmax=vmax)\n",
    "ax2.set_xticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20], rotation=90)\n",
    "ax2.set_yticks(ticks=np.arange(0, t[-1]-t[40]+1, 20), labels=t[40::20])\n",
    "ax2.set_xlabel('Cohort')\n",
    "ax2.set_ylabel('Time')\n",
    "ax2.xaxis.set_ticks_position('top')\n",
    "ax2.xaxis.set_label_position('top')\n",
    "# plt.colorbar(img2, ax=ax2)\n",
    "cbar = plt.colorbar(img1,cax=fig.add_axes([0.98, 0.11, 0.02, 0.77]), ticks=ticks)\n",
    "cbar.ax.get_yaxis().labelpad = 8\n",
    "cbar.ax.set_ylabel('Hazard rate')\n",
    "ax2.annotate(text='',xy=(35,36),xytext=(43,36),arrowprops=dict(facecolor='black', width=1.2,headwidth=6,headlength=10))\n",
    "ax2.text(51.5,36,'Period effect\\nstarts here',fontsize=9, ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('Fig3.pdf', format='pdf', bbox_inches = \"tight\")\n",
    "if export_figs_to_xlsx:\n",
    "    data = DLM_cohort.hz[40:,40:]\n",
    "    df = pd.DataFrame(data=data, index=pd.MultiIndex.from_product([t[40:]], names=['time']), columns=t[40:])\n",
    "    df_to_excel_SI(excel_SI,df,'Figure 3A')\n",
    "if export_figs_to_xlsx:\n",
    "    data = DLM_period.hz[40:,40:]\n",
    "    df = pd.DataFrame(data=data, index=pd.MultiIndex.from_product([t[40:]], names=['time']), columns=t[40:])\n",
    "    df_to_excel_SI(excel_SI,df,'Figure 3B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
